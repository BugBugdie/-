### 1.llama2 中使用的注意力机制是什么?手写实现下分组注意力。
### 2.了解 langchain 吗?讲讲其结构。
### 3.对位置编码熟悉吗?讲讲几种位置编码的异同
### 4.RLHF的具体工程是什么?包含了哪几个模型?
### 5.分别讲讲 encoder-only、decoder-only、encoder-decoder 几种大模型的代表作。
### 6.具体讲讲 p-tuning、lora 等微调方法，并指出它们与传统fine-tuning微调有何不同。
### 7.显存不够一般怎么解决的?
### 8.几种主流大模型的 loss 了解过吗? 有哪些异同?
### 9.了解半精度训练吗?展开讲讲。
### 10.deepspeed 用过吗? 展开讲讲。