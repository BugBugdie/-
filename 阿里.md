### 1.llama2 中使用的注意力机制是什么?手写实现下分组注意力。
    llama2的是GQA，Group-Query-Attention，Q被拆分为多个组，每组Q对应一对KV
    glm是MQA，Multy-Query-Attention,只有Q是多头，KV的参数共享， 减少了KV-Cache的大小
    最基础的是MHA，Multy-Head-Attention,多头注意力

### 2.了解langchain 吗?讲讲其结构。
    
### 3.对位置编码熟悉吗?讲讲几种位置编码的异同
    Transformer的正余弦位置编码
    bert的可训练位置编码，input_ids[1,2,3,4,5] * Embedding
    Rope旋转位置编码，以绝对位置编码的方式实现相对位置编码
    
### 4.RLHF的具体工程是什么?包含了哪几个模型?
    1.RLHF，带人类反馈的强化学习。使用偏好数据集训练reward-model指导模型训练，是Policy输出符合人类偏好
    包含：Actor-model，Reward-model, Ref-model, Critic-model4个模型
    2.几个概念
    时序差分TD-error:计算的是当前状态的奖励和下一状态预期奖励之差
    贝尔曼方程：当前状态的价值（Value）等于采取当前动作获得的奖励（reward）加上下一状态的期望价值乘衰减系数
    优势函数：

### 5.分别讲讲 encoder-only、decoder-only、encoder-decoder 几种大模型的代表作。
### 6.具体讲讲 p-tuning、lora 等微调方法，并指出它们与传统fine-tuning微调有何不同。
### 7.显存不够一般怎么解决的?
### 8.几种主流大模型的 loss 了解过吗? 有哪些异同?
### 9.了解半精度训练吗?展开讲讲。
### 10.deepspeed 用过吗? 展开讲讲。